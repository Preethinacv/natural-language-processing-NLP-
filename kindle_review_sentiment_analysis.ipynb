{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d8c268",
   "metadata": {},
   "source": [
    "## Project Workflow\n",
    "\n",
    "\n",
    "### 1.Preprocessing and cleaning (feature engineering)\n",
    "### 2.Train-test split\n",
    "### 3.Feature extraction using Bag of Words, TF-IDF, or word2vec\n",
    "### 4.Training machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46da9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "import pandas as pd\n",
    "df=pd.read_csv('all_kindle_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4981eaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>11995</td>\n",
       "      <td>2183</td>\n",
       "      <td>B001DUGORO</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>Valentine cupid is a vampire- Jena and Ian ano...</td>\n",
       "      <td>02 28, 2014</td>\n",
       "      <td>A1OKS5Q1HD8WQC</td>\n",
       "      <td>lisa jon jung</td>\n",
       "      <td>jena</td>\n",
       "      <td>1393545600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>11996</td>\n",
       "      <td>6272</td>\n",
       "      <td>B002JCSFSQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>I have read all seven books in this series. Ap...</td>\n",
       "      <td>05 16, 2011</td>\n",
       "      <td>AQRSPXLNEQAMA</td>\n",
       "      <td>TerryLP</td>\n",
       "      <td>Peacekeepers Series</td>\n",
       "      <td>1305504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>11997</td>\n",
       "      <td>12483</td>\n",
       "      <td>B0035N1V7K</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>3</td>\n",
       "      <td>This book really just wasn't my cuppa.  The si...</td>\n",
       "      <td>07 26, 2013</td>\n",
       "      <td>A2T5QLT5VXOJAK</td>\n",
       "      <td>hwilson</td>\n",
       "      <td>a little creepy</td>\n",
       "      <td>1374796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>11998</td>\n",
       "      <td>3640</td>\n",
       "      <td>B001W1XT40</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>tried to use it to charge my kindle, it didn't...</td>\n",
       "      <td>09 17, 2013</td>\n",
       "      <td>A28MHD2DDY6DXB</td>\n",
       "      <td>Allison A. Slater \"Gryphon50\"</td>\n",
       "      <td>didn't work</td>\n",
       "      <td>1379376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>11999</td>\n",
       "      <td>11398</td>\n",
       "      <td>B003370JUS</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>3</td>\n",
       "      <td>Taking Instruction is a look into the often hi...</td>\n",
       "      <td>07 5, 2012</td>\n",
       "      <td>A3JUXLB4K9ZXCC</td>\n",
       "      <td>Dafna Yee</td>\n",
       "      <td>If you like BDSM with a touch of romance, this...</td>\n",
       "      <td>1341446400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0                 0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1                 1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2                 2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3                 3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4                 4        1776  B001A06VJ8   [0, 1]       4   \n",
       "...             ...         ...         ...      ...     ...   \n",
       "11995         11995        2183  B001DUGORO   [0, 0]       4   \n",
       "11996         11996        6272  B002JCSFSQ   [2, 2]       5   \n",
       "11997         11997       12483  B0035N1V7K   [0, 1]       3   \n",
       "11998         11998        3640  B001W1XT40   [1, 2]       1   \n",
       "11999         11999       11398  B003370JUS   [5, 6]       3   \n",
       "\n",
       "                                              reviewText   reviewTime  \\\n",
       "0      Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1      Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2      I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3      Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4      I did not expect this type of book to be in li...  12 31, 2012   \n",
       "...                                                  ...          ...   \n",
       "11995  Valentine cupid is a vampire- Jena and Ian ano...  02 28, 2014   \n",
       "11996  I have read all seven books in this series. Ap...  05 16, 2011   \n",
       "11997  This book really just wasn't my cuppa.  The si...  07 26, 2013   \n",
       "11998  tried to use it to charge my kindle, it didn't...  09 17, 2013   \n",
       "11999  Taking Instruction is a look into the often hi...   07 5, 2012   \n",
       "\n",
       "           reviewerID                   reviewerName  \\\n",
       "0      A3HHXRELK8BHQG                         Ridley   \n",
       "1      A2RGNZ0TRF578I                   Holly Butler   \n",
       "2      A3S0H2HV6U1I7F                        Merissa   \n",
       "3       AC4OQW3GZ919J                     Cleargrace   \n",
       "4      A3C9V987IQHOQD                       Rjostler   \n",
       "...               ...                            ...   \n",
       "11995  A1OKS5Q1HD8WQC                  lisa jon jung   \n",
       "11996   AQRSPXLNEQAMA                        TerryLP   \n",
       "11997  A2T5QLT5VXOJAK                        hwilson   \n",
       "11998  A28MHD2DDY6DXB  Allison A. Slater \"Gryphon50\"   \n",
       "11999  A3JUXLB4K9ZXCC                      Dafna Yee   \n",
       "\n",
       "                                                 summary  unixReviewTime  \n",
       "0                               Entertaining But Average      1283385600  \n",
       "1                                Terrific menage scenes!      1381190400  \n",
       "2                                       Snapdragon Alley      1397174400  \n",
       "3                                 very light murder cozy      1404518400  \n",
       "4                                                   Book      1356912000  \n",
       "...                                                  ...             ...  \n",
       "11995                                               jena      1393545600  \n",
       "11996                                Peacekeepers Series      1305504000  \n",
       "11997                                    a little creepy      1374796800  \n",
       "11998                                        didn't work      1379376000  \n",
       "11999  If you like BDSM with a touch of romance, this...      1341446400  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fba01b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aislinn is a little girl with big dreams. Afte...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3\n",
       "1  Great short read.  I didn't want to put it dow...       5\n",
       "2  I'll start by saying this is the first of four...       3\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4  I did not expect this type of book to be in li...       4\n",
       "5  Aislinn is a little girl with big dreams. Afte...       5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['reviewText','rating']]\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e81ef127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1a4fdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mising values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37f06503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db2fe1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18aecd7",
   "metadata": {},
   "source": [
    "### preprocessing and cleaning\n",
    "\n",
    "####  For sentiment analysis, we simplify the rating into binary categories: negative and positive. Ratings less than 3 are labeled as negative (0), and ratings greater than or equal to 3 are labeled as positive (1). This transformation is applied using a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c8db90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17860\\2831832760.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rating']=df['rating'].apply(lambda x:0 if x<3 else 1)\n"
     ]
    }
   ],
   "source": [
    "#positive review as 1 and negative review as 0\n",
    "df['rating']=df['rating'].apply(lambda x:0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "322d1689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7987aa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c6d0c",
   "metadata": {},
   "source": [
    "### Text Preprocessing Steps\n",
    "We perform several preprocessing steps on the review text to prepare it for modeling:\n",
    "\n",
    "#### Convert all text to lowercase.\n",
    "#### Remove special characters.\n",
    "#### Remove stopwords.\n",
    "#### Remove URLs and email addresses.\n",
    "#### Remove HTML tags.\n",
    "#### Remove extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8253178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17860\\1670793158.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "#lower all cases\n",
    "df['reviewText']=df['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46784668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#clean the data-> remove all special characters\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13f32b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs and emails\n",
    "    text = re.sub(r'(http|https|ftp|ssh)://[^\\s]+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    # Remove special characters except alphanumeric and spaces\n",
    "    text = re.sub(r'[^a-z0-9 ]', ' ', text)\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join words back\n",
    "    text = ' '.join(words)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3960bc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17860\\2002816991.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'lxml').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    jace rankin may short nothing mess man hauled ...\n",
      "1    great short read want put read one sitting sex...\n",
      "2    start saying first four books expecting conclu...\n",
      "3    aggie angela lansbury carries pocketbooks inst...\n",
      "4    expect type book library pleased find price right\n",
      "Name: reviewText, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17860\\1141955168.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "df['reviewText'] = df['reviewText'].apply(clean_text)\n",
    "print(df['reviewText'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15408537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#lemmitizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79fa1692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    jace rankin may short nothing mess man hauled ...\n",
      "1    great short read want put read one sitting sex...\n",
      "2    start saying first four book expecting conclud...\n",
      "3    aggie angela lansbury carry pocketbook instead...\n",
      "4    expect type book library pleased find price right\n",
      "Name: reviewText, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17860\\732714106.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].apply(lemmatize_text)\n"
     ]
    }
   ],
   "source": [
    "df['reviewText'] = df['reviewText'].apply(lemmatize_text)\n",
    "print(df['reviewText'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a916a4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 9600\n",
      "Testing samples: 2400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['reviewText'], df['rating'], test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Training samples: {len(X_train)}')\n",
    "print(f'Testing samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f40a8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7101d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_bow = bow.fit_transform(x_train)\n",
    "x_test_bow = bow.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18b2862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f0f07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting Sparse Matrices to Arrays\n",
    "x_train_bow = x_train_bow.toarray()\n",
    "x_test_bow = x_test_bow.toarray()\n",
    "x_train_tfidf = x_train_tfidf.toarray()\n",
    "x_test_tfidf = x_test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6cff543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model_bow = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af6f6dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model_bow.fit(x_train_bow, y_train)\n",
    "nb_model_tfidf = GaussianNB()\n",
    "nb_model_tfidf.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7814cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow = nb_model_bow.predict(x_test_bow)\n",
    "y_pred_tfidf = nb_model_tfidf.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20e0562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Accuracy: 0.5654166666666667\n",
      "TF-IDF Accuracy: 0.5720833333333334\n",
      "Bag of Words Confusion Matrix:\n",
      "[[509 294]\n",
      " [749 848]]\n",
      "TF-IDF Confusion Matrix:\n",
      "[[490 313]\n",
      " [714 883]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print('Bag of Words Accuracy:', accuracy_score(y_test, y_pred_bow))\n",
    "print('TF-IDF Accuracy:', accuracy_score(y_test, y_pred_tfidf))\n",
    "print('Bag of Words Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_bow))\n",
    "print('TF-IDF Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859a168",
   "metadata": {},
   "source": [
    "Bag of Words and TF-IDF are used to convert text data into vectors for machine learning models.\n",
    "The CountVectorizer and TfidfVectorizer from sklearn are used for feature extraction.\n",
    "Gaussian Naive Bayes is applied to both Bag of Words and TF-IDF features.\n",
    "The accuracy for both models is around 58%, indicating that Word2Vec may perform better on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ede60127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17860\\4147323060.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['reviewText'].apply(tokenize)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z ]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "df['tokens'] = df['reviewText'].apply(tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "791e66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences=df['tokens'],\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8855ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sent_vector(tokens, model):\n",
    "    vec = np.zeros(model.vector_size)\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vec += model.wv[word]\n",
    "            count += 1\n",
    "    return vec / count if count else vec\n",
    "\n",
    "X_w2v = np.array([sent_vector(t, w2v) for t in df['tokens']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbb8e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Accuracy: 0.76875\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_w2v, df['rating'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_w2v = LogisticRegression(max_iter=1000)\n",
    "model_w2v.fit(x_train, y_train)\n",
    "\n",
    "y_pred_w2v = model_w2v.predict(x_test)\n",
    "print(\"Word2Vec Accuracy:\", accuracy_score(y_test, y_pred_w2v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d82fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
